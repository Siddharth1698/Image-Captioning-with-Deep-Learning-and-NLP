{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "neflr2yu7a0q"
      },
      "source": [
        "! pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "CPy6FRVY7hbX",
        "outputId": "e42b68b1-e587-43f3-bf8c-5ae7413da2b7"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9a01a522-835e-47ec-b6da-54047cab4016\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9a01a522-835e-47ec-b6da-54047cab4016\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HLKyB3a7wyU"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPBgnvjc72Cg"
      },
      "source": [
        "# ! kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpKDXlmu9Pkk"
      },
      "source": [
        "# URL : https://towardsdatascience.com/downloading-kaggle-datasets-directly-into-google-colab-c8f0f407d73a\n",
        "\n",
        "# ! kaggle datasets download -d hsankesara/flickr-image-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnmdBq4Z_MPq",
        "outputId": "bd26fca9-eb9c-40eb-9967-2c2918f02be4"
      },
      "source": [
        "!kaggle datasets download -d hsankesara/flickr-image-dataset -p /content/sample_data/ --unzip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading flickr-image-dataset.zip to /content/sample_data\n",
            "100% 8.15G/8.16G [02:06<00:00, 162MB/s]\n",
            "100% 8.16G/8.16G [02:06<00:00, 69.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0jMKT3mmB3W",
        "outputId": "ca5c4782-5ecf-43e3-e901-97333f7e8e64"
      },
      "source": [
        "!rm \"/content/sample_data/flickr-image-dataset.zip\"\n",
        "\n",
        "print(\"Zip File deleted..\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/sample_data/flickr-image-dataset.zip': No such file or directory\n",
            "Zip File deleted..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDls9t03_eGn"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKmDYaixAsB9"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKJVwQ4K_jAS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1ed96ac-4f74-45ce-dd48-94054af096a7"
      },
      "source": [
        "import os\n",
        "\n",
        "os.listdir(\"/content/sample_data/flickr30k_images\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['results.csv', 'flickr30k_images']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ephEKHQ3Atgs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8eade0ff-ce67-41bb-d413-b9c04e11bcfd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "url = \"/content/sample_data/flickr30k_images/results.csv\"\n",
        "\n",
        "df = pd.read_csv(url, delimiter = \"|\")\n",
        "\n",
        "\n",
        "\n",
        "# metadata = metadata.dropna()\n",
        "# is_NaN = metadata.isnull()\n",
        "# row_has_NaN = is_NaN.any(axis=1)\n",
        "# rows_with_NaN = metadata[row_has_NaN]\n",
        "# print(rows_with_NaN)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>comment_number</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>Two young guys with shaggy hair look at their...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>Two young , White males are outside near many...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>Two men in green shirts are standing in a yard .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>A man in a blue shirt standing in a garden .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>Two friends enjoy time spent together .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       image_name  ...                                            comment\n",
              "0  1000092795.jpg  ...   Two young guys with shaggy hair look at their...\n",
              "1  1000092795.jpg  ...   Two young , White males are outside near many...\n",
              "2  1000092795.jpg  ...   Two men in green shirts are standing in a yard .\n",
              "3  1000092795.jpg  ...       A man in a blue shirt standing in a garden .\n",
              "4  1000092795.jpg  ...            Two friends enjoy time spent together .\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlG9NmVRIT7R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "183d45f2-259c-4359-9670-e46dcfe140b4"
      },
      "source": [
        "# identify the size of data frame\n",
        "print(\"Size of the data frame is\",df.size)\n",
        "\n",
        "# identify the shape of the data frame \n",
        "print(\"Shape of the data frame is\",df.shape)\n",
        "print(\"No of Rows = \", df.shape[0])\n",
        "print(\"No of Columns = \", df.shape[1])\n",
        "\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the data frame is 476745\n",
            "Shape of the data frame is (158915, 3)\n",
            "No of Rows =  158915\n",
            "No of Columns =  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>comment_number</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>158915</td>\n",
              "      <td>158915</td>\n",
              "      <td>158914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>31783</td>\n",
              "      <td>6</td>\n",
              "      <td>158438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>4875329519.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>Two dogs playing in the snow .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>5</td>\n",
              "      <td>31783</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            image_name  comment_number                          comment\n",
              "count           158915          158915                           158914\n",
              "unique           31783               6                           158438\n",
              "top     4875329519.jpg               1   Two dogs playing in the snow .\n",
              "freq                 5           31783                                7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vrds-MVCHqs"
      },
      "source": [
        "# ***Handling Missing Values***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7P1nUOTCFVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c95f8a-f9b5-4c81-8004-432e6cf60463"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 158915 entries, 0 to 158914\n",
            "Data columns (total 3 columns):\n",
            " #   Column           Non-Null Count   Dtype \n",
            "---  ------           --------------   ----- \n",
            " 0   image_name       158915 non-null  object\n",
            " 1    comment_number  158915 non-null  object\n",
            " 2    comment         158914 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 3.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMXovmPGCgEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3409b9c8-cab3-4ab1-ef13-98c61dc383b2"
      },
      "source": [
        "miss_count = df.isnull().sum().sum()\n",
        "\n",
        "print(\"No of missing values is\",miss_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of missing values is 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5s_kA-YCkDO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "11a4d913-e98a-44f1-938e-ea10e29c0df3"
      },
      "source": [
        "# Get rows where the data is missing\n",
        "null_data = df[df.isnull().any(axis=1)]\n",
        "null_data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>comment_number</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>2199200615.jpg</td>\n",
              "      <td>4   A dog runs across the grass .</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           image_name                      comment_number  comment\n",
              "19999  2199200615.jpg   4   A dog runs across the grass .      NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKHKrnaQIlrb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "84ee7969-8828-44d0-9c85-05785289fec4"
      },
      "source": [
        "import missingno as msno\n",
        "# ! pip install missingno\n",
        "\n",
        "missing_bar  = msno.bar(df, figsize=(6, 3), fontsize=12, color='magenta')\n",
        "\n",
        "print(missing_bar)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AxesSubplot(0.125,0.125;0.775x0.755)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_B-u14DJQq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69446ff3-ef47-47bb-922b-2121bbce69bc"
      },
      "source": [
        "df = df.dropna()\n",
        "\n",
        "miss_count = df.isnull().sum().sum()\n",
        "\n",
        "print(\"No of missing values is\",miss_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of missing values is 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9EknWF8JXOG"
      },
      "source": [
        "# Exploartory data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBDRNGW9JXZv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcWbagriK4TP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQn-eeMbK5r2"
      },
      "source": [
        "# **Prepocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec0SAKr_Nz6_"
      },
      "source": [
        " ### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyZH4MWZN1Vr"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPNHC-ScK86P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a14e3f5-f614-4814-cfc5-bf271599a66d"
      },
      "source": [
        "text = df[\" comment\"][0]\n",
        "print(text)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(text)\n",
        "t = tokenizer.texts_to_sequences(text)\n",
        "\n",
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Two young guys with shaggy hair look at their hands while hanging out in the yard .\n",
            "{'h': 1, 't': 2, 'g': 3, 'i': 4, 'a': 5, 'o': 6, 'n': 7, 'y': 8, 'w': 9, 'u': 10, 's': 11, 'r': 12, 'e': 13, 'l': 14, 'd': 15, 'k': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AmIdYhlOLcY"
      },
      "source": [
        "def tokenize(text):\n",
        "  tokenizer = Tokenizer()\n",
        "\n",
        "  tokenizer.fit_on_texts(text)\n",
        "  t = tokenizer.texts_to_sequences(text)\n",
        "\n",
        "  return tokenizer, t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn4HVHKyOinY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e9b986f-d82c-4a84-8d2d-0acf23977aee"
      },
      "source": [
        "texts = list([df[\" comment\"][0], df[\" comment\"][1]])\n",
        "print(texts)\n",
        "\n",
        "for text in texts:\n",
        "  tokenizer, t = tokenize(text)\n",
        "  print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' Two young guys with shaggy hair look at their hands while hanging out in the yard .', ' Two young , White males are outside near many bushes .']\n",
            "{'h': 1, 't': 2, 'g': 3, 'i': 4, 'a': 5, 'o': 6, 'n': 7, 'y': 8, 'w': 9, 'u': 10, 's': 11, 'r': 12, 'e': 13, 'l': 14, 'd': 15, 'k': 16}\n",
            "{'e': 1, 'a': 2, 's': 3, 't': 4, 'o': 5, 'u': 6, 'n': 7, 'w': 8, 'y': 9, 'h': 10, 'i': 11, 'm': 12, 'r': 13, 'g': 14, 'l': 15, 'd': 16, 'b': 17}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOPHlFLxQ1w0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e41273-acf5-47e1-ff7d-e6a9a9e5c78f"
      },
      "source": [
        "def tokenize(x):\n",
        "    \"\"\"\n",
        "    Tokenize x\n",
        "    :param x: List of sentences/strings to be tokenized\n",
        "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
        "    \"\"\"\n",
        "    tokenizer=Tokenizer()\n",
        "    tokenizer.fit_on_texts(x)\n",
        "    t=tokenizer.texts_to_sequences(x)\n",
        "    # TODO: Implement\n",
        "    return t, tokenizer\n",
        "\n",
        "# Tokenize Example output\n",
        "text_sentences = [\n",
        "    'The quick brown fox jumps over the lazy dog .',\n",
        "    'By Jove , my quick study of lexicography won a prize .',\n",
        "    'This is a short sentence .']\n",
        "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
        "print(text_tokenizer.word_index)\n",
        "print()\n",
        "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
        "    print('Sequence {} in x'.format(sample_i + 1))\n",
        "    print('  Input:  {}'.format(sent))\n",
        "    print('  Output: {}'.format(token_sent))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n",
            "\n",
            "Sequence 1 in x\n",
            "  Input:  The quick brown fox jumps over the lazy dog .\n",
            "  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
            "Sequence 2 in x\n",
            "  Input:  By Jove , my quick study of lexicography won a prize .\n",
            "  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
            "Sequence 3 in x\n",
            "  Input:  This is a short sentence .\n",
            "  Output: [18, 19, 3, 20, 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSei_VnGQlfv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nHNsRNzQlr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def5523c-96a6-4078-f4a6-4ffb3693244a"
      },
      "source": [
        "def pad(x, length=None):\n",
        "  \"\"\"\n",
        "  Pad x\n",
        "  :param x: List of sequences.\n",
        "  :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
        "  :return: Padded numpy array of sequences\n",
        "  \"\"\"\n",
        "  # TODO: Implement\n",
        "  padding=pad_sequences(x,padding='post',maxlen=length)\n",
        "  return padding\n",
        "\n",
        "# Pad Tokenized output\n",
        "test_pad = pad(text_tokenized)\n",
        "\n",
        "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
        "  print('Sequence {} in x'.format(sample_i + 1))\n",
        "  print('  Input:  {}'.format(np.array(token_sent)))\n",
        "  print('  Output: {}'.format(pad_sent))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence 1 in x\n",
            "  Input:  [1 2 4 5 6 7 1 8 9]\n",
            "  Output: [1 2 4 5 6 7 1 8 9 0]\n",
            "Sequence 2 in x\n",
            "  Input:  [10 11 12  2 13 14 15 16  3 17]\n",
            "  Output: [10 11 12  2 13 14 15 16  3 17]\n",
            "Sequence 3 in x\n",
            "  Input:  [18 19  3 20 21]\n",
            "  Output: [18 19  3 20 21  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blDFXUhIQ8I2"
      },
      "source": [
        "Read the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QOkAi91RNIg"
      },
      "source": [
        "def load_image(name):\n",
        "  \n",
        "  img = image.load_img(name,target_size=(32,32,3))\n",
        "  img = image.img_to_array(img)\n",
        "  #img = img/255\n",
        "  #plt.imshow(img)\n",
        "  img = np.reshape(img,(32*32*3))\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnafIMgfRew1"
      },
      "source": [
        "image_arr = []\n",
        "sentence_arr = []\n",
        "\n",
        "for ind in range(5000):\n",
        "\n",
        "  if ind % 5 != 0:\n",
        "      continue\n",
        "\n",
        "  image_location = (df.iloc[ind,:]['image_name'])\n",
        "  sentence = (df.iloc[ind,:][' comment'])\n",
        "  \n",
        "  \n",
        "  image_arr.append(load_image(\"/content/sample_data/flickr30k_images/flickr30k_images/\"+ str(image_location)) )\n",
        "  sentence_arr.append('<SOS>'+sentence+'<EOS>')\n",
        "  \n",
        "        \n",
        "Images =  np.array(image_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYYYyh_ZQ8Vt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03cdb0a5-d2a9-44cc-cfe9-13a53b5108ff"
      },
      "source": [
        "def preprocess(sentences):\n",
        "  text_tokenized, text_tokenizer = tokenize(sentences)\n",
        "  text_pad = pad(text_tokenized)\n",
        "  return text_pad, text_tokenizer\n",
        "\n",
        "Sentence , token_Sentence = preprocess(sentence_arr)\n",
        "Sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  2,  17,  21, ...,   0,   0,   0],\n",
              "       [  2, 105,  37, ...,   0,   0,   0],\n",
              "       [  2,   1,  49, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [  2,   1, 296, ...,   0,   0,   0],\n",
              "       [  2,   1,  21, ...,   0,   0,   0],\n",
              "       [  2,   1,  15, ...,   0,   0,   0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1Xr0MqUgL8v",
        "outputId": "d3408252-9099-4f99-86d6-277e5e4d38ff"
      },
      "source": [
        "token_Sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_preprocessing.text.Tokenizer at 0x7f00cddcef10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQXxYwTOgFLk"
      },
      "source": [
        "import pickle\n",
        "\n",
        "#save it\n",
        "with open(f'token_Sentence.pickle', 'wb') as file:\n",
        "    pickle.dump(token_Sentence, file) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YTVKLLwR0LN"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_batch(src, tar , batchsize , i):\n",
        "\n",
        "  src, tar =  np.transpose(src[(i-1)*batchsize : (i-1)*batchsize + batchsize]) , np.transpose(tar[(i-1)*batchsize : (i-1)*batchsize + batchsize])\n",
        "\n",
        "  return torch.tensor(src).long(),torch.tensor(tar).long()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDUnxvvMSNXL"
      },
      "source": [
        "# PyTorch Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIUAdxdfSMXG"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ_nVu9FSTE4"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(\n",
        "    self,\n",
        "    embedding_size,\n",
        "    src_vocab_size,\n",
        "    trg_vocab_size,\n",
        "    src_pad_idx,\n",
        "    num_heads,\n",
        "    num_encoder_layers,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len_s,\n",
        "    max_len_t,\n",
        "    device,\n",
        "):\n",
        "    super(Transformer, self).__init__()\n",
        "    self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
        "    self.src_position_embedding = nn.Embedding(max_len_s, embedding_size)\n",
        "    self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
        "    self.trg_position_embedding = nn.Embedding(max_len_t, embedding_size)\n",
        "\n",
        "    self.device = device\n",
        "    self.transformer = nn.Transformer(\n",
        "        embedding_size,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "    )\n",
        "    self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.src_pad_idx = src_pad_idx\n",
        "\n",
        "  def make_src_mask(self, src):\n",
        "    src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "\n",
        "    # (N, src_len)\n",
        "    return src_mask.to(self.device)\n",
        "\n",
        "  def forward(self, src, trg):\n",
        "    src_seq_length, N = src.shape\n",
        "    trg_seq_length, N = trg.shape\n",
        "\n",
        "    src_positions = (\n",
        "        torch.arange(0, src_seq_length)\n",
        "        .unsqueeze(1)\n",
        "        .expand(src_seq_length, N)\n",
        "        .to(self.device)\n",
        "    )\n",
        "\n",
        "    trg_positions = (\n",
        "        torch.arange(0, trg_seq_length)\n",
        "        .unsqueeze(1)\n",
        "        .expand(trg_seq_length, N)\n",
        "        .to(self.device)\n",
        "    )\n",
        "\n",
        "    embed_src = self.dropout(\n",
        "        (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
        "    )\n",
        "    embed_trg = self.dropout(\n",
        "        (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
        "    )\n",
        "\n",
        "    src_padding_mask = self.make_src_mask(src)\n",
        "    trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(self.device)\n",
        "    out = self.transformer(\n",
        "        embed_src,\n",
        "        embed_trg,\n",
        "        src_key_padding_mask=src_padding_mask,\n",
        "        tgt_mask=trg_mask,\n",
        "    )\n",
        "    out = self.fc_out(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpbzKmvASeYd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f5a57a-f4fc-4ac5-e57f-ccd634aa7dd9"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANDylANwShXy"
      },
      "source": [
        "# Model hyperparameters\n",
        "src_vocab_size = 256\n",
        "trg_vocab_size = len(token_Sentence.word_index)\n",
        "embedding_size = 512\n",
        "num_heads = 8\n",
        "num_encoder_layers = 3\n",
        "num_decoder_layers = 3\n",
        "dropout = 0.10\n",
        "max_len_s = Images.shape[1]\n",
        "max_len_t = len(Sentence[0])\n",
        "forward_expansion = 4\n",
        "src_pad_idx = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lMDHsRCSkFk"
      },
      "source": [
        "# Training hyperparameters\n",
        "num_epochs = 10000\n",
        "learning_rate = 3e-4\n",
        "batch_size = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjAklDOKSmG6"
      },
      "source": [
        "model = Transformer(\n",
        "    embedding_size,\n",
        "    src_vocab_size,\n",
        "    trg_vocab_size,\n",
        "    src_pad_idx,\n",
        "    num_heads,\n",
        "    num_encoder_layers,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len_s,\n",
        "    max_len_t,\n",
        "    device,\n",
        ").to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "\n",
        "pad_idx = 0\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLzphdqrSsNV"
      },
      "source": [
        "import time\n",
        "\n",
        "def train():\n",
        "  model.train() # Turn on the train mode\n",
        "  total_loss = 0\n",
        "  start_time = time.time()\n",
        "  for i in range(1, 999):\n",
        "    src,tar = create_batch(Images,Sentence, batch_size , i)\n",
        "    src = src.to(device)\n",
        "    tar = tar.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(src,tar)\n",
        "    loss = criterion(output.view(-1, output.shape[2]), tar.reshape(-1))\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "    optimizer.step()\n",
        "    cur_loss = loss.item()\n",
        "    total_loss += cur_loss\n",
        "    log_interval = 100\n",
        "    if i % log_interval == 0 and i > 0:\n",
        "        elapsed = time.time() - start_time\n",
        "        print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
        "              's/batch {:5.2f} | '\n",
        "              'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "                epoch, i, (src.shape[1]) // batch_size, \n",
        "                elapsed  / log_interval,\n",
        "                cur_loss, math.exp(cur_loss)))\n",
        "        start_time = time.time()\n",
        "  return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxV4knqYS0jn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "6cfbf46d-d136-43c9-e3e4-f36428e70885"
      },
      "source": [
        "import math\n",
        "\n",
        "for epoch in range(1):\n",
        "  epoch_start_time = time.time()\n",
        "  loss = train()\n",
        "  print('-' * 89)\n",
        "  print('| end of epoch {:3d} | time: {:5.2f}s | Training loss {:5.2f} | '\n",
        "        .format(epoch, (time.time() - epoch_start_time),\n",
        "                                    loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-18652ad5ff6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m89\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   print('| end of epoch {:3d} | time: {:5.2f}s | Training loss {:5.2f} | '\n",
            "\u001b[0;32m<ipython-input-34-b1effb4622cd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBhaIRSvdvAS"
      },
      "source": [
        "import pickle\n",
        "\n",
        "#save it\n",
        "with open(f'test_cpu.pickle', 'wb') as file:\n",
        "    pickle.dump(model, file) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "668exZlBsUiZ"
      },
      "source": [
        "# #load it\n",
        "# with open(f'test.pickle', 'rb') as file2:\n",
        "#     s1_new = pickle.load(file2)\n",
        "\n",
        "# #check it\n",
        "# s1_new.get_grade()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Sg37PKwshIp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMzuMEP0slmS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxm87M34sluI"
      },
      "source": [
        "def display_image(name):\n",
        "  img = image.load_img(name,target_size=(512,512,3))\n",
        "  img = image.img_to_array(img)\n",
        "  img = img/255\n",
        "  plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckm_Lf_asnw7"
      },
      "source": [
        "def evaluate(index):\n",
        "  image_location, sent = df.iloc[index,0], df.iloc[index,2]\n",
        "  image_arr = []\n",
        "  img = load_image('/content/sample_data/flickr30k_images/flickr30k_images/'+str(image_location))\n",
        "  image_arr.append(img)\n",
        "  img_arr = np.array(image_arr)\n",
        "  sentence = []\n",
        "  sentence.append(sent)\n",
        "  sentence[0] = '<SOS> '+sentence[0]+'<EOS>'\n",
        "  sentence = pad(token_Sentence.texts_to_sequences(sentence) , length = max_len_t)\n",
        "  src , tar = create_batch(img_arr,sentence, 1,1)\n",
        "  src = src.to(device)\n",
        "  tar = tar.to(device)\n",
        "  model.eval()\n",
        "  output =  model(src,tar)\n",
        "  loss = criterion(output.view(-1, output.shape[2]), tar.reshape(-1))\n",
        "  sentence_formed = ''\n",
        "  val, ind = torch.max(output.view(-1, output.shape[2]), 1)\n",
        "  for word in ind:\n",
        "      #print('--->'+sentence_formed+'    '+str(word.item()))\n",
        "      if word.item() == 3: # EOS\n",
        "              break\n",
        "      for key, value in token_Sentence.word_index.items():\n",
        "          #print(value == word.item())\n",
        "          if value == word.item() and value != 2: # sos\n",
        "              sentence_formed = sentence_formed + key +' '\n",
        "              break\n",
        "  display_image('/content/sample_data/flickr30k_images/flickr30k_images/'+str(image_location))\n",
        "  return sentence_formed , loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MT-kZqAsrot"
      },
      "source": [
        "evaluate(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQlKOhVTtD47"
      },
      "source": [
        "evaluate(10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}